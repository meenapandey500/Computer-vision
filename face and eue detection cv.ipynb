{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boxed-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "potential-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier(r'images\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=cv2.imread(r'images\\Rekha_in_2019.jpg')\n",
    "#gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.imread(r'images\\images2.jpg')\n",
    "#img=cv2.resize(img,(300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consistent-winter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 21  54  45  45]\n",
      " [128  29  44  44]\n",
      " [234  27  46  46]]\n"
     ]
    }
   ],
   "source": [
    "faces=face_cascade.detectMultiScale(img)\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varying-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continent-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eye Detection With OpenCV\n",
    "\n",
    "'''detecMultiScale() function is for detecting objects if it finds a face in the image it will return \n",
    "in the form of x,y,w,h. and it needs some parameters.\n",
    "\n",
    "ScaleFactor: This is parameter is for specifying  how much the image size is reduced at \n",
    "each image scale.\n",
    "\n",
    "minNeighbors: Parameter specifying how many neighbors each candidate rectangle should have to\n",
    "retain it, this parameter will affect the quality of the detected faces.'''\n",
    "\n",
    "import cv2\n",
    " \n",
    " \n",
    " \n",
    "image = cv2.imread(r'images\\Rekha_in_2019.jpg')\n",
    "eye_cascade = cv2.CascadeClassifier(r'images\\haarcascade_eye.xml')\n",
    "eyes = eye_cascade.detectMultiScale(image, scaleFactor = 1.1, minNeighbors = 5)\n",
    " \n",
    " \n",
    "for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(image,(ex,ey),(ex+ew,ey+eh),(255,0,0),5)\n",
    " \n",
    " \n",
    " \n",
    "cv2.imshow(\"Eye Detected\", image)\n",
    " \n",
    " \n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "auburn-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographic-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier(r'images\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peaceful-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,img=cap.read()\n",
    "    faces=face_cascade.detectMultiScale(img)\n",
    "    print(faces)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,0),3)\n",
    "    cv2.imshow('Image',img)\n",
    "    if cv2.waitKey(0)==27 :\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(r'images\\haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(r'images\\haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "img = cv2.imread(r'images\\images2.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "     roi_gray = gray[y:y+h, x:x+w]\n",
    "     roi_color = img[y:y+h, x:x+w]\n",
    "     eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "     for (ex,ey,ew,eh) in eyes:\n",
    "         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Algorithm :\n",
    "\n",
    "\n",
    "The frame is captured and converted to grayscale.\n",
    "Bilateral Filtering is applied to remove impurities.\n",
    "Face is detected with the haarcascade.\n",
    "The ROI (Region Of Image) of Face is fed to eye detection part of algorithm.\n",
    "Eyes are detected and resulting list is passed to if-else contruct.\n",
    "If the length of list is more than two, means that the eyes are there.\n",
    "Else the program is marked to be eye blinked and restarted.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "labeled-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the imports go here\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Initializing the face and eye cascade classifiers from xml files\n",
    "face_cascade = cv2.CascadeClassifier(r'images\\haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(r'images\\haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "\n",
    "  \n",
    "#Variable store execution state\n",
    "first_read = True\n",
    "  \n",
    "#Starting the video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret,img = cap.read()\n",
    "  \n",
    "while(ret):\n",
    "    ret,img = cap.read()\n",
    "    #Coverting the recorded image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #Applying filter to remove impurities\n",
    "    gray = cv2.bilateralFilter(gray,5,1,1)\n",
    "  \n",
    "    #Detecting the face for region of image to be fed to eye classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5,minSize=(200,200))\n",
    "    if(len(faces)>0):\n",
    "        for (x,y,w,h) in faces:\n",
    "            img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "  \n",
    "            #roi_face is face which is input to eye classifier\n",
    "            roi_face = gray[y:y+h,x:x+w]\n",
    "            roi_face_clr = img[y:y+h,x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_face,1.3,5,minSize=(50,50))\n",
    "  \n",
    "            #Examining the length of eyes object for eyes\n",
    "            if(len(eyes)>=2):\n",
    "                #Check if program is running for detection \n",
    "                if(first_read):\n",
    "                    cv2.putText(img, \n",
    "                    \"Eye detected press s to begin\", \n",
    "                    (70,70),  \n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                    (0,255,0),2)\n",
    "                else:\n",
    "                    cv2.putText(img, \n",
    "                    \"Eyes open!\", (70,70), \n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                    (255,255,255),2)\n",
    "            else:\n",
    "                if(first_read):\n",
    "                    #To ensure if the eyes are present before starting\n",
    "                    cv2.putText(img, \n",
    "                    \"No eyes detected\", (70,70),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                    (0,0,255),2)\n",
    "                else:\n",
    "                    #This will print on console and restart the algorithm\n",
    "                    print(\"Blink detected--------------\")\n",
    "                    cv2.waitKey(3000)\n",
    "                    first_read=True\n",
    "              \n",
    "    else:\n",
    "        cv2.putText(img,\n",
    "        \"No face detected\",(100,100),\n",
    "        cv2.FONT_HERSHEY_PLAIN, 3, \n",
    "        (0,255,0),2)\n",
    "  \n",
    "    #Controlling the algorithm with keys\n",
    "    cv2.imshow('img',img)\n",
    "    a = cv2.waitKey(1)\n",
    "    if(a==ord('q')):\n",
    "        break\n",
    "    elif(a==ord('s') and first_read):\n",
    "        #This will start the detection\n",
    "        first_read = False\n",
    "  \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weird-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    " \n",
    " \n",
    "image = cv2.imread(r'images\\Rekha_in_2019.jpg')\n",
    "eye_cascade = cv2.CascadeClassifier(r'images\\haarcascade_eye.xml')\n",
    "eyes = eye_cascade.detectMultiScale(image, scaleFactor = 1.1, minNeighbors = 5)\n",
    " \n",
    " \n",
    "for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(image,(ex,ey),(ex+ew,ey+eh),(255,0,0),5)\n",
    " \n",
    " \n",
    " \n",
    "cv2.imshow(\"Eye Detected\", image)\n",
    " \n",
    " \n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-saturday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
